{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare all libraries and their uses here\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing data types and non-null counts of each column of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing all the counts of each unique value in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df.columns\n",
    "\n",
    "for column in column_names:\n",
    "    print(df[column].value_counts())\n",
    "    print(\"\\n************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify any columns having null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df = df.isnull().sum().to_frame()\n",
    "null_df.loc[null_df[0]!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and drop columns mostly null values \n",
    "As columns having more than 70% missing values should have no significant effect on the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_null = ['s59','s57','s56','s55','s54']\n",
    "df.drop(majority_null, axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label encoding for binary categorical data. (Only two options eg: M/F, Y/N). Identified from column value counts. Done using scikit.learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating instance of label encoder from scikit.learn\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# columns to encode\n",
    "label_encode = ['gender','s11','s12','s53','s58']\n",
    "\n",
    "# use encoder on each of the selected columns\n",
    "for column in label_encode:\n",
    "    df[column] = label_encoder.fit_transform(df[column])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use one-hot encoding instead of label encoding for non-binary categories, as it is unclear whether data is ordinal or not, to avoid unintentional ranking and therfore bias. Done using get_dummies from pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to encode\n",
    "one_hot_encode = ['s16','s17','s18','s69','s70','s71']\n",
    "\n",
    "# create dummy columns for each possible value \n",
    "# in each of the columns \n",
    "# (auto prefixed with original column name)\n",
    "ohe_df = pd.get_dummies(df[one_hot_encode])\n",
    "\n",
    "# Drop each of the original columns in the original dataframe \n",
    "# as they are now encoded\n",
    "df = df.drop(columns=one_hot_encode, axis = 1)\n",
    "\n",
    "# Join the dataframe with the encoded columns \n",
    "# to the original dataframe\n",
    "df = df.join(ohe_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_mapping_dict = {\n",
    "    \"l\": \"1\",\n",
    "    \"o\": \"0\"\n",
    "}\n",
    "df['s52'] = df['s52'].apply(lambda x: x.replace(replacement_mapping_dict, regex=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can do multiple replacements in within one call of the replace method by creating a mapping dictionary\n",
    "# very scalable woo\n",
    "\n",
    "df['s52'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the encoded categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df.columns\n",
    "\n",
    "for column in column_names:\n",
    "    print(df[column].value_counts())\n",
    "    print(\"\\n************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving Target column 'label' to the right\n",
    "df=df[[c for c in df if c not in ['label']] \n",
    "       + ['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[['s16_A', 's16_B', 's16_C', 's16_D']]\n",
    "df_test_2 =df[['s17_A','s17_B', 's17_C', 's17_D']]\n",
    "df_test_3 =df[['s18_A', 's18_B', 's18_C', 's18_D']]\n",
    "df_test_4 =df[['s69_0','s69_C`', 's69_x', 's69_~1']]\n",
    "df_test_5 =df[[ 's70_op: A', 's70_op: B', 's70_op: C','s70_op: D']]\n",
    "df_test_6 =df[['s71_a', 's71_b', 's71_c', 's71_d']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variance Inflation Factor function to check for multicollinearity\n",
    "def variance(df):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = df.columns\n",
    "    \n",
    "    # calculating VIF for each feature\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df.values, i)\n",
    "                            for i in range(len(df.columns))]\n",
    "    print(vif_data)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "\n",
    "# dataplot = sns.heatmap(df_test, cmap=\"YlGnBu\", annot = True)\n",
    "  \n",
    "# displaying heatmap\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc= df[['n1','n2','n4','n5','n6','n7','n8','n9','n10','n11','n14']]\n",
    "normalized_df=(df_desc-df_desc.mean())/df_desc.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df[[ 'gender', 's11', 's12', 's13', 's48', 's52', 's53', 's58', 'n1',\n",
    "       'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'n10', 'n11', 'n12',\n",
    "       'n13', 'n14', 'n15', 's16_A', 's16_B', 's16_C', 's16_D', 's17_A',\n",
    "       's17_B', 's17_C', 's17_D', 's18_A', 's18_B', 's18_C', 's18_D', 's69_0',\n",
    "       's69_C`', 's69_x', 's69_~1', 's70_op: A', 's70_op: B', 's70_op: C',\n",
    "       's70_op: D', 's71_a', 's71_b', 's71_c', 's71_d']]\n",
    "       \n",
    "df_2[['n1','n2','n4','n5','n6','n7','n8','n9','n10','n11','n14']] = normalized_df[['n1','n2','n4','n5','n6','n7','n8','n9','n10','n11','n14']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df_2\n",
    "y= df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1).fit(X, y) # X= features of training set, y= target value of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0606053452435824a427f0ea93d6ae20786397642025bcc66bfe96b66155d44b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
